{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of neural networks architectures for segmentation problem:\n",
    "1. Fully Convolutional Network\n",
    "2. U-Net\n",
    "3. SegNet\n",
    "4. PSPNet: Pyramid Scene Parsing Network\n",
    "5. DeepLab\n",
    "\n",
    "FCN works as a Encoder and Decoder. It first version had only one layer in Decoder. \n",
    "The U-Net architecture is built upon the Fully Convolutional Network. Compared to FCN-8, the two main differences are U-net is symmetric and the skip connections between the downsampling path and the upsampling path apply a concatenation operator instead of a sum. As consequencies, the number of parameters of the model is reduced and it can be trained with a small labelled dataset (using appropriate data augmentation). \n",
    "SegNet doesn’t have strong difference with U-Net. An article about SegNet says:\n",
    "«As compared to SegNet, U-Net does not reuse pooling indices but instead transfers the entire feature map (at the cost of more memory) to the corresponding decoders and concatenates them to upsampled (via deconvolution) decoder feature maps. There is no conv5 and max-pool 5 block in U-Net as in the VGG net architecture. SegNet, on the other hand, uses all of the pre-trained convolutional layer weights from VGG net as pre-trained weights». [1]\n",
    "\n",
    "PSPNet was developed to better learn the global context representation of a scene. They are pooled with four different scales each one corresponding to a pyramid level and processed by a 1x1 convolutional layer to reduce their dimensions. This way each pyramid level analyses sub-regions of the image with different location.  \n",
    "DeepLab combining atrous convolution, spatial pyramid pooling and fully connected CRFs.\n",
    "\n",
    "U-Net was chosen for this task as one of the most popular architecture with good benchmarks. \n",
    "\n",
    "As a loss for neural network was chosen a sum of dice coefficient and binary cross entropy to archive better differentiable properties and dealing with imbalanced classes. \n",
    "\n",
    " Adam was choosen for its speed.\n",
    "\n",
    "[1] https://arxiv.org/pdf/1511.00561.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"path\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from torchvision import transforms\n",
    "\n",
    "from lib import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "data_train_path = \"data/train\"\n",
    "data_val_path = \"data/val\"\n",
    "jpg_format = \"jpg\"\n",
    "png_format = \"png\"\n",
    "class_number = 1\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "augmentation_pipeline = A.Compose(\n",
    "    [\n",
    "        A.GaussNoise(var_limit=(10, 100), p=1),\n",
    "        A.Blur(10, p=1),\n",
    "        A.RGBShift(p=1),\n",
    "        A.RandomRotate90(always_apply=True),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                # apply one of transforms to 50% of image\n",
    "                A.RandomGamma(),  # apply random gamma\n",
    "                A.RandomBrightness(0.1),  # apply random brightness\n",
    "            ],\n",
    "            p=0.5\n",
    "        )\n",
    "    ],\n",
    "    p=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_train_dataset = BasicDataset(data_train_path, jpg_format, trans)\n",
    "basic_train_aug_dataset = BasicDataset(data_train_path, jpg_format, trans, augmentation_pipeline)\n",
    "basic_val_dataset = BasicDataset(data_val_path, png_format, trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': DataLoader(basic_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(basic_val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "model = UNet(class_number)\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model = train_model(model, optimizer_ft, dataloaders, device, batch_size, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first version of neural network was created without data augmentation. But it had some problems in validation data set. Here is an example:\n",
    "![%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202020-02-18%20%D0%B2%2018.52.56.png](attachment:%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202020-02-18%20%D0%B2%2018.52.56.png)\n",
    "You can see, that the subject is blured with enviroment with a close color. So data augmentation was performed in the way to solve this problem, it was done with blur, also was added rotate for better learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': DataLoader(basic_train_dataset + basic_train_aug_dataset, batch_size=batch_size, shuffle=True,\n",
    "                        num_workers=0),\n",
    "    'val': DataLoader(basic_val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "model = UNet(class_number)\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model, metrics = train_model(model, optimizer_ft, dataloaders, device, batch_size, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result for UNet with augmentation:\n",
    "\n",
    "Epoch 10/19\n",
    "_______\n",
    "LR 1e-05\n",
    "train: bce: 0.004201, dice: 0.056958, loss: 0.030580\n",
    "\n",
    "val: bce: 0.010855, dice: 0.134940, loss: 0.072898\n",
    "\n",
    "saving best model\n",
    "\n",
    "12m 32s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(class_number)\n",
    "model.load_state_dict(torch.load(\"pretrained_model/model.pth\"))  # works with gpu, was trained on colab, the best model with data\n",
    "#augmentation\n",
    "model.eval()\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(TestDataset(\"data/real_test\", \"JPG\", 4, trans), batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=0)\n",
    "\n",
    "pred_masks_dict = get_pred_masks(model, test_data_loader, device)\n",
    "paths = [\"data/real_test/000%s.JPG\" % x.numpy()[0] for x in list(pred_masks_dict.keys())]\n",
    "pred_masks = list(pred_masks_dict.values())\n",
    "_ = get_html(paths, pred_masks, path_to_save=\"results/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(TestDataset(\"/content/drive/My Drive/data/val/images\", \"png\", 8, trans),\n",
    "                              batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "pred_masks_dict = get_pred_masks(model, test_data_loader, device)\n",
    "pred_masks_dict = {k.numpy()[0]: encode_rle(v) for k, v in pred_masks_dict.items()}\n",
    "df = pd.DataFrame.from_dict(pred_masks_dict, orient='index', columns=[\"rle_mask\"])\n",
    "df[\"img_id\"] = df.index\n",
    "df = df[['img_id', 'rle_mask']]\n",
    "df.to_csv(\"pred_val_template.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting results and looking at results on real_test, we can see some problems of our current model. The one problem is with colors. Can also be solved with data augmentation, but takes a lot of time and resources to train neural network.\n",
    "Also we can try different learning rate and optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
